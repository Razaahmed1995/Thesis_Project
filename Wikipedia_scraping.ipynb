{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19092c6",
   "metadata": {},
   "source": [
    "# Specifying CURL command and creating a python script of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bee10ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6141\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_article_list(cmcontinue=''):\n",
    "    headers = {\n",
    "        'Accept-Encoding': 'gzip,deflate',\n",
    "    }\n",
    "\n",
    "    params = (\n",
    "        ('action', 'query'),\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "      'list': 'categorymembers',\n",
    "      'cmtitle': 'Category:Featured_articles',\n",
    "      'cmlimit': '500',\n",
    "      'action': 'query',\n",
    "      'format' : 'json',\n",
    "      'cmcontinue' : cmcontinue\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://en.wikipedia.org/w/api.php', headers=headers,data=data)\n",
    "    d = json.loads(response.content)\n",
    "    if 'continue' in d.keys():\n",
    "        cmcontinue = d['continue']['cmcontinue']\n",
    "    else:\n",
    "        cmcontinue = ''\n",
    "    titles = [elem['title'] for elem in d['query']['categorymembers']]\n",
    "    return titles, cmcontinue\n",
    "\n",
    "titles, cmcontinue = get_article_list()\n",
    "featured_articles = titles\n",
    "\n",
    "while len(titles) == 500:\n",
    "    titles, cmcontinue = get_article_list(cmcontinue)\n",
    "    featured_articles.extend(titles)\n",
    "    print(len(featured_articles))\n",
    "\n",
    "for idx, title in enumerate(featured_articles):\n",
    "    featured_articles[idx] = title.replace(' ','_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c41971d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def retrieve_article_revisions(articlename, timestamp=''):\n",
    "    \n",
    "    headers = {\n",
    "        'Accept-Encoding': 'gzip,deflate',\n",
    "    }\n",
    "\n",
    "    params = (\n",
    "        ('title', 'Special:Export'),\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "      'pages': articlename,\n",
    "      'offset': timestamp,\n",
    "      'limit': '1000',\n",
    "      'action': 'submit'\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://en.wikipedia.org/w/index.php', headers=headers, params=params, data=data)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def retrieve_article(articlename):\n",
    "    timestamp = ''\n",
    "    xml_list = []\n",
    "    num = 1000\n",
    "    \n",
    "    while num == 1000:\n",
    "        data = retrieve_article_revisions(articlename, timestamp)\n",
    "        timestamp, num = get_timestamp_from_xml(BytesIO(data))\n",
    "        print('Retrieved {} revisions from article about {}, last from {}'.format(num, articlename, timestamp))\n",
    "        xml_list.append(data)\n",
    "    \n",
    "    return xml_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6d38e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 868 revisions from article about 243_Ida, last from 2022-09-11T05:51:35Z\n",
      "Retrieved 687 revisions from article about 509th_Composite_Group, last from 2022-07-19T23:48:08Z\n",
      "Retrieved 231 revisions from article about 766th_Independent_Infantry_Regiment_(North_Korea), last from 2022-08-06T17:52:42Z\n",
      "Retrieved 755 revisions from article about 1080Â°_Snowboarding, last from 2022-09-13T15:25:45Z\n",
      "Retrieved 212 revisions from article about 1678_Kediri_campaign, last from 2022-08-06T17:55:46Z\n",
      "Retrieved 624 revisions from article about 1740_Batavia_massacre, last from 2022-09-04T04:54:31Z\n",
      "Retrieved 410 revisions from article about 1789_Virginia's_5th_congressional_district_election, last from 2022-06-14T20:27:51Z\n",
      "Retrieved 653 revisions from article about 1804_dollar, last from 2022-06-14T20:28:01Z\n",
      "Retrieved 673 revisions from article about 1838_Jesuit_slave_sale, last from 2022-07-14T23:19:12Z\n",
      "Retrieved 123 revisions from article about 1850_Atlantic_hurricane_season, last from 2022-06-14T20:28:21Z\n"
     ]
    }
   ],
   "source": [
    "featured_articles_revisions = {}\n",
    "\n",
    "for article in featured_articles[40:50]:\n",
    "    featured_articles_revisions[article] = retrieve_article(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac172e4",
   "metadata": {},
   "source": [
    "# Writing the xml files in local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "22cd8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in featured_articles_revisions.keys():\n",
    "    for idx,revision in enumerate(featured_articles_revisions[key]):\n",
    "        filename = \"{}_{}.xml\".format(key,idx)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(revision)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
